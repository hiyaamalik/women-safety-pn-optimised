{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e661aa41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS Gesture Detected!\n",
      "SMS sent: SOS Alert: Gesture detected. Location: Dadri Road, Preet Vihar, Dadri, Gautam Buddha Nagar, Uttar Pradesh, 203207, India\n",
      "\n",
      "--- Benchmark Results ---\n",
      "Face Detection: Avg Time = 0.0176s\n",
      "Person Detection: Avg Time = 0.0177s\n",
      "Gender Prediction: Avg Time = 0.0464s\n",
      "Age Prediction: Avg Time = 0.0066s\n",
      "\n",
      "--- Running Benchmark Tests ---\n",
      "\n",
      "Face Detection Model:\n",
      "\n",
      "Running Intel Benchmark for face-detection-adas-0001.xml on CPU...\n",
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 17.01 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [N,C,H,W] / [1,3,384,672]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,384,672]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 137.67 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: mobilenet_ssd_672x384\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 4\n",
      "[ INFO ]   NUM_STREAMS: 4\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 4 inference requests, limits: 100 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 12.97 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            100 iterations\n",
      "[ INFO ] Duration:         702.02 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        27.77 ms\n",
      "[ INFO ]    Average:       27.63 ms\n",
      "[ INFO ]    Min:           17.25 ms\n",
      "[ INFO ]    Max:           57.61 ms\n",
      "[ INFO ] Throughput:   142.45 FPS\n",
      "\n",
      "\n",
      "Person Detection Model:\n",
      "\n",
      "Running Intel Benchmark for person-detection-retail-0013.xml on CPU...\n",
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 21.00 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [N,C,H,W] / [1,3,320,544]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,320,544]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 240.43 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: ResMobNet_v4 (LReLU) with single SSD head\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 4\n",
      "[ INFO ]   NUM_STREAMS: 4\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 4 inference requests, limits: 100 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 13.58 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            100 iterations\n",
      "[ INFO ] Duration:         550.66 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        21.77 ms\n",
      "[ INFO ]    Average:       21.71 ms\n",
      "[ INFO ]    Min:           13.03 ms\n",
      "[ INFO ]    Max:           38.97 ms\n",
      "[ INFO ] Throughput:   181.60 FPS\n",
      "\n",
      "\n",
      "Age Model:\n",
      "\n",
      "Running Intel Benchmark for age_net.xml on CPU...\n",
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 6.00 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [...] / [1,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [1,8]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [1,8]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 50.40 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: CaffeNet\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[ WARNING ] Number of iterations was aligned by request number from 100 to 108 using number of requests 12\n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 108 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 13.92 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            108 iterations\n",
      "[ INFO ] Duration:         258.74 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        23.45 ms\n",
      "[ INFO ]    Average:       27.45 ms\n",
      "[ INFO ]    Min:           18.42 ms\n",
      "[ INFO ]    Max:           78.12 ms\n",
      "[ INFO ] Throughput:   417.42 FPS\n",
      "\n",
      "\n",
      "Gender Model:\n",
      "\n",
      "Running Intel Benchmark for gender_net.xml on CPU...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 7.00 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [...] / [10,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [10,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'data': [1,3,227,227]\n",
      "[ INFO ] Reshape model took 1.00 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 50.23 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: CaffeNet\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[ WARNING ] Number of iterations was aligned by request number from 100 to 108 using number of requests 12\n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 108 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 13.71 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            108 iterations\n",
      "[ INFO ] Duration:         266.14 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        25.32 ms\n",
      "[ INFO ]    Average:       28.27 ms\n",
      "[ INFO ]    Min:           19.36 ms\n",
      "[ INFO ]    Max:           74.36 ms\n",
      "[ INFO ] Throughput:   405.80 FPS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import geocoder\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import winsound\n",
    "\n",
    "TWILIO_ACCOUNT_SID = 'ACeee6e79bd6c3c60111f6c74ccf64f8d2'\n",
    "TWILIO_AUTH_TOKEN = '20512043644183f4033ffe0d50a562bf'\n",
    "TWILIO_PHONE_NUMBER = '+17752629110'\n",
    "TARGET_PHONE_NUMBERS = ['+918005964482']\n",
    "\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_LIST = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(21-24)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "gesture_detected = False\n",
    "single_woman_message_printed = False\n",
    "lone_woman_between_men_message_printed = False\n",
    "sos_triggered = False\n",
    "\n",
    "\n",
    "core = Core()\n",
    "\n",
    "face_detection_model = core.read_model(\"face-detection-adas-0001.xml\")\n",
    "person_detection_model = core.read_model(\"person-detection-retail-0013.xml\")\n",
    "age_model = core.read_model(\"age_net.xml\")\n",
    "gender_model = core.read_model(\"gender_net.xml\")\n",
    "\n",
    "face_compiled_model = core.compile_model(face_detection_model, \"CPU\")\n",
    "person_compiled_model = core.compile_model(person_detection_model, \"CPU\")\n",
    "age_compiled_model = core.compile_model(age_model, \"CPU\")\n",
    "gender_compiled_model = core.compile_model(gender_model, \"CPU\")\n",
    "\n",
    "\n",
    "benchmarks = {\n",
    "    \"face_detection\": [],\n",
    "    \"person_detection\": [],\n",
    "    \"age_prediction\": [],\n",
    "    \"gender_prediction\": [],\n",
    "}\n",
    "\n",
    "prediction_tracker = {\n",
    "    \"gender\": {\"correct\": 0, \"total\": 0},\n",
    "    \"age\": {\"correct\": 0, \"total\": 0},\n",
    "}\n",
    "\n",
    "\n",
    "def send_sms(message):\n",
    "    try:\n",
    "        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "        for target_phone_number in TARGET_PHONE_NUMBERS:\n",
    "            client.messages.create(\n",
    "                body=message,\n",
    "                from_=TWILIO_PHONE_NUMBER,\n",
    "                to=target_phone_number\n",
    "            )\n",
    "            print(f\"SMS sent: {message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send SMS: {e}\")\n",
    "\n",
    "\n",
    "def get_detailed_location():\n",
    "    g = geocoder.ip('me')\n",
    "    if g.latlng:\n",
    "        lat, lng = g.latlng\n",
    "        geolocator = Nominatim(user_agent=\"myGeocoder\")\n",
    "        location = geolocator.reverse((lat, lng), language='en', timeout=10)\n",
    "        if location:\n",
    "            return location.address\n",
    "    return \"Location not available\"\n",
    "\n",
    "\n",
    "def detect_faces_openvino(frame):\n",
    "    start_time = time.time()\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frame, size=(672, 384), mean=(0, 0, 0), swapRB=False, crop=False)\n",
    "    infer_request = face_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    detections = infer_request.get_output_tensor().data[0][0]\n",
    "\n",
    "    benchmarks[\"face_detection\"].append(time.time() - start_time)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    faces = []\n",
    "    for detection in detections:\n",
    "        confidence = detection[2]\n",
    "        if confidence > 0.5:\n",
    "            xmin = int(detection[3] * w)\n",
    "            ymin = int(detection[4] * h)\n",
    "            xmax = int(detection[5] * w)\n",
    "            ymax = int(detection[6] * h)\n",
    "            faces.append((xmin, ymin, xmax - xmin, ymax - ymin))\n",
    "    return faces\n",
    "\n",
    "def detect_bodies_openvino(frame):\n",
    "    start_time = time.time()\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frame, size=(544, 320), mean=(0, 0, 0), swapRB=False, crop=False)\n",
    "    infer_request = person_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    detections = infer_request.get_output_tensor().data[0][0]\n",
    "\n",
    "    benchmarks[\"person_detection\"].append(time.time() - start_time)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    bodies = []\n",
    "    for detection in detections:\n",
    "        confidence = detection[2]\n",
    "        if confidence > 0.6:\n",
    "            xmin = int(detection[3] * w)\n",
    "            ymin = int(detection[4] * h)\n",
    "            xmax = int(detection[5] * w)\n",
    "            ymax = int(detection[6] * h)\n",
    "            bodies.append((xmin, ymin, xmax - xmin, ymax - ymin))\n",
    "    return bodies\n",
    "\n",
    "def predict_gender_openvino(face_img):\n",
    "    start_time = time.time()\n",
    "\n",
    "    expected_shape = [10, 3, 227, 227]\n",
    "    blob = prepare_blob(face_img, expected_shape)\n",
    "\n",
    "    infer_request = gender_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    preds = infer_request.get_output_tensor().data[0]\n",
    "\n",
    "    benchmarks[\"gender_prediction\"].append(time.time() - start_time)\n",
    "\n",
    "    gender = GENDER_LIST[np.argmax(preds)]\n",
    "    return gender\n",
    "\n",
    "def predict_age_openvino(face_img):\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    expected_shape = [1, 3, 227, 227]\n",
    "    blob = prepare_blob(face_img, expected_shape)\n",
    "\n",
    "    infer_request = age_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    preds = infer_request.get_output_tensor().data[0]\n",
    "\n",
    "    benchmarks[\"age_prediction\"].append(time.time() - start_time)\n",
    "\n",
    "    age_group = AGE_LIST[np.argmax(preds)]\n",
    "    return age_group\n",
    "\n",
    "def prepare_blob(image, expected_shape):\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "    if expected_shape[0] > 1:  \n",
    "        padded_blob = np.zeros(expected_shape, dtype=np.float32)\n",
    "        padded_blob[0] = blob \n",
    "        return padded_blob\n",
    "    return blob  \n",
    "\n",
    "\n",
    "def run_intel_benchmark(model_path, device=\"CPU\", batch_size=1, iterations=100):\n",
    "\n",
    "    benchmark_app_path = \"benchmark_app\"  \n",
    "    \n",
    "    command = [\n",
    "        benchmark_app_path,\n",
    "        \"-m\", model_path,\n",
    "        \"-d\", device,\n",
    "        \"-b\", str(batch_size),\n",
    "        \"-niter\", str(iterations),\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nRunning Intel Benchmark for {model_path} on {device}...\")\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        print(result.stdout)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running benchmark_app: {e.stderr}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def benchmark_all_models():\n",
    "\n",
    "    print(\"\\n--- Running Benchmark Tests ---\")\n",
    "    \n",
    "    models_to_benchmark = {\n",
    "        \"Face Detection Model\": \"face-detection-adas-0001.xml\",\n",
    "        \"Person Detection Model\": \"person-detection-retail-0013.xml\",\n",
    "        \"Age Model\": \"age_net.xml\",\n",
    "        \"Gender Model\": \"gender_net.xml\",\n",
    "    }\n",
    "\n",
    "    for model_name, model_path in models_to_benchmark.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        run_intel_benchmark(model_path, device=\"CPU\", batch_size=1, iterations=100)\n",
    "\n",
    "\n",
    "def detect_gesture(frame):\n",
    "    global gesture_detected, sos_triggered\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.GaussianBlur(gray, (35, 35), 0)\n",
    "\n",
    "\n",
    "    _, thresh = cv.threshold(blur, 100, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        \n",
    "        max_contour = max(contours, key=cv.contourArea)\n",
    "        if cv.contourArea(max_contour) > 1000:\n",
    "           \n",
    "            hull = cv.convexHull(max_contour, returnPoints=False)\n",
    "            defects = cv.convexityDefects(max_contour, hull)\n",
    "\n",
    "            if defects is not None:\n",
    "                count_fingers = 0\n",
    "\n",
    "                for i in range(defects.shape[0]):\n",
    "                    s, e, f, d = defects[i, 0]\n",
    "                    start = tuple(max_contour[s][0])\n",
    "                    end = tuple(max_contour[e][0])\n",
    "                    far = tuple(max_contour[f][0])\n",
    "\n",
    "                    \n",
    "                    a = np.linalg.norm(np.array(end) - np.array(start))\n",
    "                    b = np.linalg.norm(np.array(far) - np.array(start))\n",
    "                    c = np.linalg.norm(np.array(end) - np.array(far))\n",
    "                    angle = np.arccos((b**2 + c**2 - a**2) / (2 * b * c))\n",
    "\n",
    "                    \n",
    "                    if angle <= np.pi / 2:\n",
    "                        count_fingers += 1\n",
    "                        cv.circle(frame, far, 8, [0, 0, 255], -1)\n",
    "\n",
    "                \n",
    "                if count_fingers == 2 and not gesture_detected and not sos_triggered:\n",
    "                    print(\"SOS Gesture Detected!\")\n",
    "                    gesture_detected = True\n",
    "\n",
    "                    \n",
    "                    send_sms(f\"SOS Alert: Gesture detected. Location: {get_detailed_location()}\")\n",
    "\n",
    "                   \n",
    "                    winsound.Beep(1000, 500)\n",
    "\n",
    "                    \n",
    "                    sos_triggered = True\n",
    "            cv.drawContours(frame, [max_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def process_frame_with_intel_models(frame, ground_truth=None):\n",
    "    global single_woman_message_printed, lone_woman_between_men_message_printed, sos_triggered\n",
    "    global prediction_tracker\n",
    "\n",
    "    \n",
    "    frame = detect_gesture(frame)\n",
    "\n",
    "    faces = detect_faces_openvino(frame)\n",
    "    bodies = detect_bodies_openvino(frame)\n",
    "\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        predicted_gender = predict_gender_openvino(face_img)\n",
    "        predicted_age = predict_age_openvino(face_img)\n",
    "\n",
    "  \n",
    "        if ground_truth:\n",
    "            gt_gender = ground_truth.get(\"gender\")\n",
    "            gt_age = ground_truth.get(\"age\")\n",
    "\n",
    "            if gt_gender:\n",
    "                prediction_tracker[\"gender\"][\"total\"] += 1\n",
    "                if predicted_gender == gt_gender:\n",
    "                    prediction_tracker[\"gender\"][\"correct\"] += 1\n",
    "\n",
    "            if gt_age:\n",
    "                prediction_tracker[\"age\"][\"total\"] += 1\n",
    "                if predicted_age == gt_age:\n",
    "                    prediction_tracker[\"age\"][\"correct\"] += 1\n",
    "\n",
    "        if predicted_gender == 'Male':\n",
    "            male_count += 1\n",
    "        elif predicted_gender == 'Female':\n",
    "            female_count += 1\n",
    "\n",
    "        cv.putText(frame, f\"{predicted_gender}, {predicted_age}\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    count_label = f'Males: {male_count}, Females: {female_count}'\n",
    "    cv.putText(frame, count_label, (10, frame.shape[0] - 40), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    if female_count == 1 and male_count > 2 and not sos_triggered:\n",
    "        send_sms(f\"SOS Alert: Lone woman detected. Location: {get_detailed_location()}\")\n",
    "        sos_triggered = True\n",
    "\n",
    "    return frame\n",
    "def process_frame_with_intel_models(frame, ground_truth=None):\n",
    "    global single_woman_message_printed, lone_woman_between_men_message_printed, sos_triggered\n",
    "    global prediction_tracker\n",
    "\n",
    "    frame = detect_gesture(frame)\n",
    "\n",
    "    faces = detect_faces_openvino(frame)\n",
    "    bodies = detect_bodies_openvino(frame)\n",
    "\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        predicted_gender = predict_gender_openvino(face_img)\n",
    "        predicted_age = predict_age_openvino(face_img)\n",
    "\n",
    "        if ground_truth:\n",
    "            gt_gender = ground_truth.get(\"gender\")\n",
    "            gt_age = ground_truth.get(\"age\")\n",
    "\n",
    "            if gt_gender:\n",
    "                prediction_tracker[\"gender\"][\"total\"] += 1\n",
    "                if predicted_gender == gt_gender:\n",
    "                    prediction_tracker[\"gender\"][\"correct\"] += 1\n",
    "\n",
    "            if gt_age:\n",
    "                prediction_tracker[\"age\"][\"total\"] += 1\n",
    "                if predicted_age == gt_age:\n",
    "                    prediction_tracker[\"age\"][\"correct\"] += 1\n",
    "\n",
    "        if predicted_gender == 'Male':\n",
    "            male_count += 1\n",
    "        elif predicted_gender == 'Female':\n",
    "            female_count += 1\n",
    "\n",
    "        cv.putText(frame, f\"{predicted_gender}, {predicted_age}\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    count_label = f'Males: {male_count}, Females: {female_count}'\n",
    "    cv.putText(frame, count_label, (10, frame.shape[0] - 40), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    if female_count == 1 and male_count > 2 and not sos_triggered:\n",
    "        send_sms(f\"SOS Alert: Lone woman detected. Location: {get_detailed_location()}\")\n",
    "        sos_triggered = True\n",
    "\n",
    "    return frame\n",
    "def calculate_accuracy():\n",
    "    global prediction_tracker\n",
    "\n",
    "    for category in prediction_tracker:\n",
    "        correct = prediction_tracker[category][\"correct\"]\n",
    "        total = prediction_tracker[category][\"total\"]\n",
    "        if total > 0:\n",
    "            accuracy = (correct / total) * 100\n",
    "            print(f\"{category.capitalize()} Accuracy: {accuracy:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{category.capitalize()} Accuracy: No data available.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    frame_width = 1280\n",
    "    frame_height = 720\n",
    "    cap.set(3, frame_width)\n",
    "    cap.set(4, frame_height)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"Failed to capture frame. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        processed_frame = process_frame_with_intel_models(frame)\n",
    "        cv.imshow('Intel Model Integration', processed_frame)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    print(\"\\n--- Benchmark Results ---\")\n",
    "    print(f\"Face Detection: Avg Time = {np.mean(benchmarks['face_detection']):.4f}s\")\n",
    "    print(f\"Person Detection: Avg Time = {np.mean(benchmarks['person_detection']):.4f}s\")\n",
    "    print(f\"Gender Prediction: Avg Time = {np.mean(benchmarks['gender_prediction']):.4f}s\")\n",
    "    print(f\"Age Prediction: Avg Time = {np.mean(benchmarks['age_prediction']):.4f}s\")\n",
    "\n",
    "    benchmark_all_models()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d3e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
