{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e661aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS Gesture Detected!\n",
      "SMS sent: SOS Alert: Gesture detected. Location: Ghaziabad, Uttar Pradesh, 201002, India\n",
      "\n",
      "--- Benchmark Results ---\n",
      "Face Detection: Avg Time = 0.0184s\n",
      "Person Detection: Avg Time = 0.0143s\n",
      "Gender Prediction: Avg Time = 0.0459s\n",
      "Age Prediction: Avg Time = 0.0074s\n",
      "\n",
      "--- Running Benchmark Tests ---\n",
      "\n",
      "Face Detection Model:\n",
      "\n",
      "Running Intel Benchmark for face-detection-adas-0001.xml on CPU...\n",
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 23.65 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [N,C,H,W] / [1,3,384,672]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,384,672]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 117.98 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: mobilenet_ssd_672x384\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 4\n",
      "[ INFO ]   NUM_STREAMS: 4\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 4 inference requests, limits: 100 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 9.90 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            100 iterations\n",
      "[ INFO ] Duration:         615.13 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        25.96 ms\n",
      "[ INFO ]    Average:       24.39 ms\n",
      "[ INFO ]    Min:           15.20 ms\n",
      "[ INFO ]    Max:           33.09 ms\n",
      "[ INFO ] Throughput:   162.57 FPS\n",
      "\n",
      "\n",
      "Person Detection Model:\n",
      "\n",
      "Running Intel Benchmark for person-detection-retail-0013.xml on CPU...\n",
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 19.22 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [N,C,H,W] / [1,3,320,544]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,320,544]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     detection_out (node: detection_out) : f32 / [...] / [1,1,200,7]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 231.07 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: ResMobNet_v4 (LReLU) with single SSD head\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 4\n",
      "[ INFO ]   NUM_STREAMS: 4\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 4 inference requests, limits: 100 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 11.55 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            100 iterations\n",
      "[ INFO ] Duration:         502.94 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        20.93 ms\n",
      "[ INFO ]    Average:       20.02 ms\n",
      "[ INFO ]    Min:           11.63 ms\n",
      "[ INFO ]    Max:           36.83 ms\n",
      "[ INFO ] Throughput:   198.83 FPS\n",
      "\n",
      "\n",
      "Age Model:\n",
      "\n",
      "Running Intel Benchmark for age_net.xml on CPU...\n",
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 10.14 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [...] / [1,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [1,8]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [1,8]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 50.53 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: CaffeNet\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[ WARNING ] Number of iterations was aligned by request number from 100 to 108 using number of requests 12\n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 108 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 13.01 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            108 iterations\n",
      "[ INFO ] Duration:         255.77 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        24.86 ms\n",
      "[ INFO ]    Average:       26.56 ms\n",
      "[ INFO ]    Min:           18.92 ms\n",
      "[ INFO ]    Max:           61.69 ms\n",
      "[ INFO ] Throughput:   422.25 FPS\n",
      "\n",
      "\n",
      "Gender Model:\n",
      "\n",
      "Running Intel Benchmark for gender_net.xml on CPU...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[ WARNING ] Batch size is set. Auto batching will be disabled\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 10.37 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : f32 / [...] / [10,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [10,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'data': [1,3,227,227]\n",
      "[ INFO ] Reshape model took 0.00 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     data (node: data) : u8 / [N,C,H,W] / [1,3,227,227]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     prob (node: prob) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 53.05 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: CaffeNet\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[ INFO ]   AFFINITY: Affinity.HYBRID_AWARE\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'data'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'data' with random values \n",
      "[ WARNING ] Number of iterations was aligned by request number from 100 to 108 using number of requests 12\n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 108 iterations)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 13.51 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            108 iterations\n",
      "[ INFO ] Duration:         250.99 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        25.25 ms\n",
      "[ INFO ]    Average:       27.20 ms\n",
      "[ INFO ]    Min:           20.33 ms\n",
      "[ INFO ]    Max:           63.13 ms\n",
      "[ INFO ] Throughput:   430.30 FPS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import geocoder\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import winsound\n",
    "\n",
    "# Twilio credentials (ensure these are secure in production)\n",
    "TWILIO_ACCOUNT_SID = 'ACeee6e79bd6c3c60111f6c74ccf64f8d2'\n",
    "TWILIO_AUTH_TOKEN = '20512043644183f4033ffe0d50a562bf'\n",
    "TWILIO_PHONE_NUMBER = '+17752629110'\n",
    "TARGET_PHONE_NUMBERS = ['+918005964482']\n",
    "\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_LIST = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(21-24)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "gesture_detected = False\n",
    "single_woman_message_printed = False\n",
    "lone_woman_between_men_message_printed = False\n",
    "sos_triggered = False\n",
    "\n",
    "# Initialize OpenVINO\n",
    "core = Core()\n",
    "\n",
    "# Load Intel models\n",
    "face_detection_model = core.read_model(\"face-detection-adas-0001.xml\")\n",
    "person_detection_model = core.read_model(\"person-detection-retail-0013.xml\")\n",
    "age_model = core.read_model(\"age_net.xml\")\n",
    "gender_model = core.read_model(\"gender_net.xml\")\n",
    "\n",
    "# Compile models\n",
    "face_compiled_model = core.compile_model(face_detection_model, \"CPU\")\n",
    "person_compiled_model = core.compile_model(person_detection_model, \"CPU\")\n",
    "age_compiled_model = core.compile_model(age_model, \"CPU\")\n",
    "gender_compiled_model = core.compile_model(gender_model, \"CPU\")\n",
    "\n",
    "# Benchmark storage\n",
    "benchmarks = {\n",
    "    \"face_detection\": [],\n",
    "    \"person_detection\": [],\n",
    "    \"age_prediction\": [],\n",
    "    \"gender_prediction\": [],\n",
    "}\n",
    "\n",
    "# Function to send SMS alerts\n",
    "def send_sms(message):\n",
    "    try:\n",
    "        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "        for target_phone_number in TARGET_PHONE_NUMBERS:\n",
    "            client.messages.create(\n",
    "                body=message,\n",
    "                from_=TWILIO_PHONE_NUMBER,\n",
    "                to=target_phone_number\n",
    "            )\n",
    "            print(f\"SMS sent: {message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send SMS: {e}\")\n",
    "\n",
    "# Geolocation functions\n",
    "def get_detailed_location():\n",
    "    g = geocoder.ip('me')\n",
    "    if g.latlng:\n",
    "        lat, lng = g.latlng\n",
    "        geolocator = Nominatim(user_agent=\"myGeocoder\")\n",
    "        location = geolocator.reverse((lat, lng), language='en', timeout=10)\n",
    "        if location:\n",
    "            return location.address\n",
    "    return \"Location not available\"\n",
    "\n",
    "# Detection functions\n",
    "def detect_faces_openvino(frame):\n",
    "    start_time = time.time()\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frame, size=(672, 384), mean=(0, 0, 0), swapRB=False, crop=False)\n",
    "    infer_request = face_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    detections = infer_request.get_output_tensor().data[0][0]\n",
    "\n",
    "    benchmarks[\"face_detection\"].append(time.time() - start_time)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    faces = []\n",
    "    for detection in detections:\n",
    "        confidence = detection[2]\n",
    "        if confidence > 0.5:\n",
    "            xmin = int(detection[3] * w)\n",
    "            ymin = int(detection[4] * h)\n",
    "            xmax = int(detection[5] * w)\n",
    "            ymax = int(detection[6] * h)\n",
    "            faces.append((xmin, ymin, xmax - xmin, ymax - ymin))\n",
    "    return faces\n",
    "\n",
    "def detect_bodies_openvino(frame):\n",
    "    start_time = time.time()\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frame, size=(544, 320), mean=(0, 0, 0), swapRB=False, crop=False)\n",
    "    infer_request = person_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    detections = infer_request.get_output_tensor().data[0][0]\n",
    "\n",
    "    benchmarks[\"person_detection\"].append(time.time() - start_time)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    bodies = []\n",
    "    for detection in detections:\n",
    "        confidence = detection[2]\n",
    "        if confidence > 0.6:\n",
    "            xmin = int(detection[3] * w)\n",
    "            ymin = int(detection[4] * h)\n",
    "            xmax = int(detection[5] * w)\n",
    "            ymax = int(detection[6] * h)\n",
    "            bodies.append((xmin, ymin, xmax - xmin, ymax - ymin))\n",
    "    return bodies\n",
    "\n",
    "def predict_gender_openvino(face_img):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Gender model expects batch size = 10\n",
    "    expected_shape = [10, 3, 227, 227]\n",
    "    blob = prepare_blob(face_img, expected_shape)\n",
    "\n",
    "    infer_request = gender_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    preds = infer_request.get_output_tensor().data[0]\n",
    "\n",
    "    benchmarks[\"gender_prediction\"].append(time.time() - start_time)\n",
    "\n",
    "    gender = GENDER_LIST[np.argmax(preds)]\n",
    "    return gender\n",
    "\n",
    "def predict_age_openvino(face_img):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Age model expects batch size = 1\n",
    "    expected_shape = [1, 3, 227, 227]\n",
    "    blob = prepare_blob(face_img, expected_shape)\n",
    "\n",
    "    infer_request = age_compiled_model.create_infer_request()\n",
    "    infer_request.infer({0: blob})\n",
    "    preds = infer_request.get_output_tensor().data[0]\n",
    "\n",
    "    benchmarks[\"age_prediction\"].append(time.time() - start_time)\n",
    "\n",
    "    age_group = AGE_LIST[np.argmax(preds)]\n",
    "    return age_group\n",
    "\n",
    "def prepare_blob(image, expected_shape):\n",
    "    \"\"\"\n",
    "    Prepare input blob with the correct batch size.\n",
    "    \"\"\"\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "    if expected_shape[0] > 1:  # Model expects batch size > 1\n",
    "        padded_blob = np.zeros(expected_shape, dtype=np.float32)\n",
    "        padded_blob[0] = blob  # Populate only the first input\n",
    "        return padded_blob\n",
    "    return blob  # Model expects batch size = 1\n",
    "\n",
    "\n",
    "# Intel Benchmarking Function\n",
    "def run_intel_benchmark(model_path, device=\"CPU\", batch_size=1, iterations=100):\n",
    "    \"\"\"\n",
    "    Run Intel's benchmark_app for the given model and return the result.\n",
    "    \"\"\"\n",
    "    benchmark_app_path = \"benchmark_app\"  # Ensure this is in PATH or provide full path.\n",
    "    \n",
    "    command = [\n",
    "        benchmark_app_path,\n",
    "        \"-m\", model_path,\n",
    "        \"-d\", device,\n",
    "        \"-b\", str(batch_size),\n",
    "        \"-niter\", str(iterations),\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nRunning Intel Benchmark for {model_path} on {device}...\")\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        print(result.stdout)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running benchmark_app: {e.stderr}\")\n",
    "        return None\n",
    "\n",
    "# Call Benchmarking for Each Model\n",
    "def benchmark_all_models():\n",
    "    \"\"\"\n",
    "    Run benchmarks for all models used in the pipeline.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Running Benchmark Tests ---\")\n",
    "    \n",
    "    models_to_benchmark = {\n",
    "        \"Face Detection Model\": \"face-detection-adas-0001.xml\",\n",
    "        \"Person Detection Model\": \"person-detection-retail-0013.xml\",\n",
    "        \"Age Model\": \"age_net.xml\",\n",
    "        \"Gender Model\": \"gender_net.xml\",\n",
    "    }\n",
    "\n",
    "    for model_name, model_path in models_to_benchmark.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        run_intel_benchmark(model_path, device=\"CPU\", batch_size=1, iterations=100)\n",
    "\n",
    "\n",
    "\n",
    "# Add a new function for gesture detection\n",
    "def detect_gesture(frame):\n",
    "    global gesture_detected, sos_triggered\n",
    "\n",
    "    # Convert the frame to grayscale and apply Gaussian blur\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.GaussianBlur(gray, (35, 35), 0)\n",
    "\n",
    "    # Apply threshold\n",
    "    _, thresh = cv.threshold(blur, 100, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the largest contour by area\n",
    "        max_contour = max(contours, key=cv.contourArea)\n",
    "        if cv.contourArea(max_contour) > 1000:\n",
    "            # Create a convex hull\n",
    "            hull = cv.convexHull(max_contour, returnPoints=False)\n",
    "            defects = cv.convexityDefects(max_contour, hull)\n",
    "\n",
    "            if defects is not None:\n",
    "                count_fingers = 0\n",
    "\n",
    "                for i in range(defects.shape[0]):\n",
    "                    s, e, f, d = defects[i, 0]\n",
    "                    start = tuple(max_contour[s][0])\n",
    "                    end = tuple(max_contour[e][0])\n",
    "                    far = tuple(max_contour[f][0])\n",
    "\n",
    "                    # Use cosine rule to find angle\n",
    "                    a = np.linalg.norm(np.array(end) - np.array(start))\n",
    "                    b = np.linalg.norm(np.array(far) - np.array(start))\n",
    "                    c = np.linalg.norm(np.array(end) - np.array(far))\n",
    "                    angle = np.arccos((b**2 + c**2 - a**2) / (2 * b * c))\n",
    "\n",
    "                    # Count as a finger if angle is less than 90 degrees\n",
    "                    if angle <= np.pi / 2:\n",
    "                        count_fingers += 1\n",
    "                        cv.circle(frame, far, 8, [0, 0, 255], -1)\n",
    "\n",
    "                # If one finger and thumb are detected\n",
    "                if count_fingers == 2 and not gesture_detected and not sos_triggered:\n",
    "                    print(\"SOS Gesture Detected!\")\n",
    "                    gesture_detected = True\n",
    "\n",
    "                    # Send SOS message\n",
    "                    send_sms(f\"SOS Alert: Gesture detected. Location: {get_detailed_location()}\")\n",
    "\n",
    "                    # Beep sound\n",
    "                    winsound.Beep(1000, 500)\n",
    "\n",
    "                    # Avoid multiple SOS triggers\n",
    "                    sos_triggered = True\n",
    "            cv.drawContours(frame, [max_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Update the frame processing function to include gesture detection\n",
    "def process_frame_with_intel_models(frame):\n",
    "    global single_woman_message_printed, lone_woman_between_men_message_printed, sos_triggered\n",
    "\n",
    "    # Add gesture detection\n",
    "    frame = detect_gesture(frame)\n",
    "\n",
    "    faces = detect_faces_openvino(frame)\n",
    "    bodies = detect_bodies_openvino(frame)\n",
    "\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        gender = predict_gender_openvino(face_img)\n",
    "        age = predict_age_openvino(face_img)\n",
    "\n",
    "        if gender == 'Male':\n",
    "            male_count += 1\n",
    "        elif gender == 'Female':\n",
    "            female_count += 1\n",
    "\n",
    "        cv.putText(frame, f\"{gender}, {age}\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    count_label = f'Males: {male_count}, Females: {female_count}'\n",
    "    cv.putText(frame, count_label, (10, frame.shape[0] - 40), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # SOS alert for lone woman detection\n",
    "    if female_count == 1 and male_count > 2 and not sos_triggered:\n",
    "        send_sms(f\"SOS Alert: Lone woman detected. Location: {get_detailed_location()}\")\n",
    "        sos_triggered = True\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Main loop\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    frame_width = 1280\n",
    "    frame_height = 720\n",
    "    cap.set(3, frame_width)\n",
    "    cap.set(4, frame_height)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"Failed to capture frame. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        processed_frame = process_frame_with_intel_models(frame)\n",
    "        cv.imshow('Intel Model Integration', processed_frame)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # Display Benchmark Results\n",
    "    print(\"\\n--- Benchmark Results ---\")\n",
    "    print(f\"Face Detection: Avg Time = {np.mean(benchmarks['face_detection']):.4f}s\")\n",
    "    print(f\"Person Detection: Avg Time = {np.mean(benchmarks['person_detection']):.4f}s\")\n",
    "    print(f\"Gender Prediction: Avg Time = {np.mean(benchmarks['gender_prediction']):.4f}s\")\n",
    "    print(f\"Age Prediction: Avg Time = {np.mean(benchmarks['age_prediction']):.4f}s\")\n",
    "\n",
    "    # Run Intel Benchmark for each model\n",
    "    benchmark_all_models()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca5e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d3e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
