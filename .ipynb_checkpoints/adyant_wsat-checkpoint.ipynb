{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c720d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] MO command line tool is considered as the legacy conversion API as of OpenVINO 2023.2 release.\n",
      "In 2025.0 MO command line tool and openvino.tools.mo.convert_model() will be removed. Please use OpenVINO Model Converter (OVC) or openvino.convert_model(). OVC represents a lightweight alternative of MO and provides simplified model conversion API. \n",
      "Find more information about transition from MO to OVC at https://docs.openvino.ai/2023.2/openvino_docs_OV_Converter_UG_prepare_model_convert_model_MO_OVC_transition.html\n",
      "Please expect that Model Optimizer conversion might be slow. You are currently using Python protobuf library implementation. \n",
      "Check that your protobuf package version is aligned with requirements_caffe.txt.\n",
      "\n",
      "\n",
      " For more information please refer to Model Conversion API FAQ, question #80. (https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html?question=80#question-80)\n",
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2023-1&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: C:\\Users\\whora\\Desktop\\Adyant\\code\\age_net.xml\n",
      "[ SUCCESS ] BIN file: C:\\Users\\whora\\Desktop\\Adyant\\code\\age_net.bin\n",
      "[ INFO ] MO command line tool is considered as the legacy conversion API as of OpenVINO 2023.2 release.\n",
      "In 2025.0 MO command line tool and openvino.tools.mo.convert_model() will be removed. Please use OpenVINO Model Converter (OVC) or openvino.convert_model(). OVC represents a lightweight alternative of MO and provides simplified model conversion API. \n",
      "Find more information about transition from MO to OVC at https://docs.openvino.ai/2023.2/openvino_docs_OV_Converter_UG_prepare_model_convert_model_MO_OVC_transition.html\n",
      "Please expect that Model Optimizer conversion might be slow. You are currently using Python protobuf library implementation. \n",
      "Check that your protobuf package version is aligned with requirements_caffe.txt.\n",
      "\n",
      "\n",
      " For more information please refer to Model Conversion API FAQ, question #80. (https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html?question=80#question-80)\n",
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2023-1&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: C:\\Users\\whora\\Desktop\\Adyant\\code\\gender_net.xml\n",
      "[ SUCCESS ] BIN file: C:\\Users\\whora\\Desktop\\Adyant\\code\\gender_net.bin\n"
     ]
    }
   ],
   "source": [
    "!mo --input_model age_net.caffemodel --input_proto age_deploy.prototxt --framework caffe\n",
    "!mo --input_model gender_net.caffemodel --input_proto gender_deploy.prototxt --framework caffe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70c7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS sent: SOS Triggered!!! Location: Jodhpur, Jodhpur Tehsil, Jodhpur, Rajasthan, 112001, India\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import geocoder\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "import winsound\n",
    "\n",
    "TWILIO_ACCOUNT_SID = '*************'\n",
    "TWILIO_AUTH_TOKEN = '***********************'\n",
    "TWILIO_PHONE_NUMBER = '*************'\n",
    "TARGET_PHONE_NUMBERS = ['*****************']\n",
    "\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_LIST = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(21,24)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "single_woman_message_printed = False\n",
    "lone_woman_between_men_message_printed = False\n",
    "sos_triggered = False\n",
    "\n",
    "core = Core()\n",
    "age_model = core.read_model(\"age_net.xml\")\n",
    "gender_model = core.read_model(\"gender_net.xml\")\n",
    "age_compiled_model = core.compile_model(age_model, \"CPU\")\n",
    "gender_compiled_model = core.compile_model(gender_model, \"CPU\")\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def send_sms(message):\n",
    "    try:\n",
    "        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "        for target_phone_number in TARGET_PHONE_NUMBERS:\n",
    "            client.messages.create(\n",
    "                body=message,\n",
    "                from_=TWILIO_PHONE_NUMBER,\n",
    "                to=target_phone_number\n",
    "            )\n",
    "            print(f\"SMS sent: {message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send SMS: {e}\")\n",
    "\n",
    "def get_location():\n",
    "    g = geocoder.ip('me')\n",
    "    return g.latlng\n",
    "\n",
    "def get_detailed_location():\n",
    "    g = geocoder.ip('me')\n",
    "    if g.latlng:\n",
    "        lat, lng = g.latlng\n",
    "        geolocator = Nominatim(user_agent=\"myGeocoder\")\n",
    "        location = geolocator.reverse((lat, lng), language='en', timeout=10)\n",
    "        if location:\n",
    "            return location.address\n",
    "    return \"Location not available\"\n",
    "\n",
    "def preprocess_image(face, target_batch_size=10, is_age_model=False):\n",
    "    blob = cv.dnn.blobFromImage(face, 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "    \n",
    "    if is_age_model:\n",
    "        return blob\n",
    "    else:\n",
    "        padded_blob = np.zeros((target_batch_size, *blob.shape[1:]), dtype=np.float32)\n",
    "        padded_blob[0] = blob\n",
    "        return padded_blob\n",
    "\n",
    "def predict_age_gender_openvino(face_img):\n",
    "    gender_blob = preprocess_image(face_img, target_batch_size=10, is_age_model=False)\n",
    "    \n",
    "    gender_infer_request = gender_compiled_model.create_infer_request()\n",
    "    gender_infer_request.infer({0: gender_blob})\n",
    "    gender_preds = gender_infer_request.get_output_tensor().data[0]\n",
    "    gender = GENDER_LIST[np.argmax(gender_preds)]\n",
    "    \n",
    "    age_blob = preprocess_image(face_img, target_batch_size=1, is_age_model=True)\n",
    "    \n",
    "    age_infer_request = age_compiled_model.create_infer_request()\n",
    "    age_infer_request.infer({0: age_blob})\n",
    "    age_preds = age_infer_request.get_output_tensor().data[0]\n",
    "    age = AGE_LIST[np.argmax(age_preds)]\n",
    "    \n",
    "    return gender, age\n",
    "\n",
    "def detect_gesture(frame):\n",
    "    global sos_triggered\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv.threshold(blurred, 60, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv.findContours(thresh.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv.contourArea)\n",
    "        area = cv.contourArea(largest_contour)\n",
    "\n",
    "        \n",
    "        if area > 6000:\n",
    "            x, y, w, h = cv.boundingRect(largest_contour)\n",
    "\n",
    "            if w > h * 1.5:\n",
    "                if not sos_triggered:\n",
    "                    sos_triggered = True\n",
    "                    location = get_detailed_location()\n",
    "                    send_sms(f\"SOS Triggered!!! Location: {location}\")\n",
    "                    winsound.Beep(1000, 1000)\n",
    "                    return \"Thumb-Up (SOS Trigger)\"\n",
    "\n",
    "            elif h > w:\n",
    "                if not sos_triggered:\n",
    "                    sos_triggered = True\n",
    "                    location = get_detailed_location()\n",
    "                    send_sms(f\"SOS Triggered!!! Location: {location}\")\n",
    "                    winsound.Beep(1500, 1000)\n",
    "                    return \"Fist Gesture (SOS Trigger)\"\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def process_frame(frame):\n",
    "    global single_woman_message_printed, lone_woman_between_men_message_printed\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        gender, age = predict_age_gender_openvino(face_img)\n",
    "        \n",
    "        if gender == 'Male':\n",
    "            male_count += 1\n",
    "        elif gender == 'Female':\n",
    "            female_count += 1\n",
    "        \n",
    "        label = f'{gender}, {age}'\n",
    "        cv.putText(frame, label, (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    gesture = detect_gesture(frame)\n",
    "    \n",
    "    count_label = f'Males: {male_count}, Females: {female_count}'\n",
    "    cv.putText(frame, count_label, (10, frame.shape[0] - 40), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    if female_count == 1 and not single_woman_message_printed:\n",
    "        print(\"Single woman detected\")\n",
    "        single_woman_message_printed = True  \n",
    "    if male_count > 1 and female_count == 1 and not lone_woman_between_men_message_printed:\n",
    "        print(\"Lone woman between men\")\n",
    "        lone_woman_between_men_message_printed = True  \n",
    "    \n",
    "    return frame\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "frame_width = 1280\n",
    "frame_height = 720\n",
    "cap.set(3, frame_width)\n",
    "cap.set(4, frame_height)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    processed_frame = process_frame(frame)\n",
    "    \n",
    "    processed_frame_resized = cv.resize(processed_frame, (frame_width, frame_height))\n",
    "    \n",
    "    cv.imshow('Adyant Project N', processed_frame_resized)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42419d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
